<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Personal Projects | Mayank Kumar Pal</title>
<meta name="keywords" content="">
<meta name="description" content="Note : Please follow the provided link(s) in each project for full details. Also, some of the project title have hyperlink which navigates directly to the project page.
Visualizing Deep Learning Optimization Algorithms Description: Gradient based algorithms is the key to optimize the deep neural networks. Apart from the vanilla gradient descent algorithm, there exists many variant of gradient based algorithms which can improve the speed of convergence and can avoid local minima too.">
<meta name="author" content="">
<link rel="canonical" href="https://mynkpl1998.github.io/projects/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.879895b4d5fd89ce0beb4dc2d2820888f6abc1370be8438465503ddda25669ae.css" integrity="sha256-h5iVtNX9ic4L603C0oIIiParwTcL6EOEZVA93aJWaa4=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://mynkpl1998.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://mynkpl1998.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://mynkpl1998.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://mynkpl1998.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://mynkpl1998.github.io/safari-pinned-tab.svg">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Fira+Sans:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://mynkpl1998.github.io/projects/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript><meta property="og:title" content="Personal Projects" />
<meta property="og:description" content="Note : Please follow the provided link(s) in each project for full details. Also, some of the project title have hyperlink which navigates directly to the project page.
Visualizing Deep Learning Optimization Algorithms Description: Gradient based algorithms is the key to optimize the deep neural networks. Apart from the vanilla gradient descent algorithm, there exists many variant of gradient based algorithms which can improve the speed of convergence and can avoid local minima too." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mynkpl1998.github.io/projects/" /><meta property="article:section" content="" />



<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Personal Projects"/>
<meta name="twitter:description" content="Note : Please follow the provided link(s) in each project for full details. Also, some of the project title have hyperlink which navigates directly to the project page.
Visualizing Deep Learning Optimization Algorithms Description: Gradient based algorithms is the key to optimize the deep neural networks. Apart from the vanilla gradient descent algorithm, there exists many variant of gradient based algorithms which can improve the speed of convergence and can avoid local minima too."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Personal Projects",
      "item": "https://mynkpl1998.github.io/projects/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Personal Projects",
  "name": "Personal Projects",
  "description": "Note : Please follow the provided link(s) in each project for full details. Also, some of the project title have hyperlink which navigates directly to the project page.\nVisualizing Deep Learning Optimization Algorithms Description: Gradient based algorithms is the key to optimize the deep neural networks. Apart from the vanilla gradient descent algorithm, there exists many variant of gradient based algorithms which can improve the speed of convergence and can avoid local minima too.",
  "keywords": [
    
  ],
  "articleBody": "Note : Please follow the provided link(s) in each project for full details. Also, some of the project title have hyperlink which navigates directly to the project page.\nVisualizing Deep Learning Optimization Algorithms Description: Gradient based algorithms is the key to optimize the deep neural networks. Apart from the vanilla gradient descent algorithm, there exists many variant of gradient based algorithms which can improve the speed of convergence and can avoid local minima too. In this project, various Deep learning optimization algorithmswere studied and their speed of convergence were visualized using PyTorch. Visualization of various deep learning optimization algorithms implemented using PyTorchâ€™s automatic differentiation tool and optimizers. It demonstrates how the iterative methods approaches to the minimum in the case of convex, non-convex surfaces and surfaces with saddle point. Source Code: https://github.com/mynkpl1998/Deep-Learning-Optimization-Algorithms Some visualizations: Recurrent Deep-Q Learning Description: Partially Observable Markov Decision Process (POMDP) is a generalization of Markov Decision Process where agent cannot directly observe the underlying state and only an observation is available. Earlier methods suggests to maintain a belief (a pmf) over all the possible states which encodes the probability of being in each state. This quickly limits the size of the problem to which we can use this method. However, the paper Playing Atari with Deep Reinforcement Learning presented an approach which uses last 4 observations as input to the learning algorithm, which can be seen as 4th order markov decision process. Many papers suggest that much performance can be obtained if we use more than last 4 frames but this is expensive from computational and storage point of view (experience replay). Recurrent networks can be used to summarize what agent has seen in past observations. In this project, I investgated this using a simple Partially Observable Environment and found that using a single recurrent layer able to achieve much better performance than using some last k-frames. Source Code: https://github.com/mynkpl1998/Recurrent-Deep-Q-Learning Results: The figure given below compares the performance of different cases. MDP case is the best we can do as the underlying state is fully visible to the agent. However, the challenge is to perform better given an observation. The graph clearly shows the LSTM consistently performed better as the total reward per episode was much higher than using some last k-frames. A Deep Reinforcement Learning Framework Description: This framework implements the various state of the art Value based Deep Reinforcement Learning algorithms, supports OpenAI gym environments out of the box. Implementation include Deep-Q learning, Deep-Q learning with target freezing, Prioritized experience replay, Double Q-learning. Source Code: https://github.com/mynkpl1998/Deep-RL-Framework Asynchronous Actor-Critic (A3C) - Policy Gradients Methods Description: High quality implementation of A3C algorithm with Generalized Advantage Estimation. Supports different neural network based policies out of the box. Performance of the algorithm scales linearly with the number of cores. Source Code: https://github.com/mynkpl1998/A3C/tree/dev Trained Policies: Deep learning for Physical layer Description: We present and discuss the application of Deep Learning (DL) for the physical layer. By interpreting a communication system as an AutoEncoder, we develop a fundamental new way to think about communications system design as end-to-end reconstruction task that seeks to jointly optimize transmitter and receiver components in a single process. Simulations were done to illustrate the learning of the deep networks. Further, the results were compared with traditional methods. Report: https://drive.google.com/file/d/1q3Ba741gZxWAgv4t7ERwb5H93iajp2J-/view Modeling communication system as end-to-end learning system: Implemention of Convolutional and Recurrent neural networks inference for Heterogeneous Devices (GPU and FPGA) using OpenCL Description: Many devices today have more than one processor other than CPUs to accelerate certain workloads. For example, an integrated graphics or DSPs in an embedded system. This creates an interesting opportunity for deep learning community to take advantage of it and use it to accelerate the inference/training process for edge devices. We attempted to implement the inference of some of the known architecture like Recurrent and Convolutional neural networks for FPGA and GPU in Open Compute Language trained on standard datasets. CNN Source Code: https://bitbucket.org/mynkpl1998/vgg_opencl/src/master/ RNN Source Code: https://bitbucket.org/mynkpl1998/rnn_opencl/src/master/ CNN Report: https://drive.google.com/file/d/1yDCyucwo6I5Z2bOd-tKOkEWo-ByrFHdc/view RNN Report: https://drive.google.com/file/d/1GzoLjMLM-rKMvbgFPtIJ7b3X_wivbxfw/view Results: The following screnshots shows the running time in case of GPU(left) and resource usage in FPGA(right). ATP-Predict Description: We carried out a brief implementation of the paper Identification of ATP binding residues of a protein from its primary sequence and attempted to improve on the existing methods by using different machine learning techniques using an extended dataset and optimized parameters on the models. We obtained maximum cross-validation accuracy of around 0.64 on a balanced data-set, with window size 17. Project Web Page: https://mynkpl1998.github.io/atppredict/ Cancer Prediction using Deep Neural Networks Description: This project investigates the opportunities of applying the deep convolutional networks fordeveloping prediction model for cancer prediction. We selected high quality image dataset containing both benign and malignant examples. We build a classifier which used SIFT to extract the features from the images. However, we found that this naive approach could not able to perform well on our dataset. We then explored the space of Deep Learning techniques specifically Deep Convolutional Neural Networks. Report: https://drive.google.com/file/d/1W24dv9um3QGnfZsEoDO-jFaOmISeWiDF/view Results: Visualizing VGG16 feature maps in Keras Description: This project impelements the code for visualizing the feature maps of VGG16 Convoutional Neural Network using Keras. Particular layer of the network can be visualized by defining it as an output layer. For brevity please check some examples given below. Source Code: https://github.com/mynkpl1998/visualize-vgg16 Feature maps: ",
  "wordCount" : "882",
  "inLanguage": "en",
  "datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://mynkpl1998.github.io/projects/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Mayank Kumar Pal",
    "logo": {
      "@type": "ImageObject",
      "url": "https://mynkpl1998.github.io/favicon.ico"
    }
  }
}
</script>


<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>
</head>

<body class="" id="top">

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://mynkpl1998.github.io/" accesskey="h" title="Mayank Kumar Pal (Alt + H)">
                <img src="https://mynkpl1998.github.io/command.svg" alt="" aria-label="logo"
                    height="25">Mayank Kumar Pal</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://mynkpl1998.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://mynkpl1998.github.io/blog/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="https://mynkpl1998.github.io/publications/" title="Publications">
                    <span>Publications</span>
                </a>
            </li>
            <li>
                <a href="https://mynkpl1998.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://mynkpl1998.github.io/projects/" title="Projects">
                    <span class="active">Projects</span>
                </a>
            </li>
        </ul>
    </nav>
    <hr class="dashed" style="border-width:2px">
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Personal Projects
    </h1>
    <div class="post-meta">

</div>
  </header> 
  <div class="post-content"><p><em>Note : Please follow the provided link(s) in each project for full details. Also, some of the project title have hyperlink which navigates directly to the project page.</em></p>
<table>
<thead>
<tr>
<th style="text-align:left"><a href="https://github.com/mynkpl1998/Deep-Learning-Optimization-Algorithms">Visualizing Deep Learning  Optimization Algorithms</a></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>Description</strong>: Gradient based algorithms is the key to optimize the deep neural networks. Apart from the vanilla gradient descent algorithm, there exists many variant of gradient based algorithms which can  improve the speed of convergence and can avoid local minima too. In this project, various Deep learning optimization algorithmswere studied and their speed of convergence were visualized using PyTorch. Visualization of various deep learning optimization algorithms implemented using PyTorchâ€™s automatic differentiation tool and optimizers. It demonstrates how the iterative methods approaches to the minimum in the case of convex, non-convex surfaces and surfaces with saddle point.</td>
</tr>
<tr>
<td style="text-align:left"><strong>Source Code</strong>: <a href="https://github.com/mynkpl1998/Deep-Learning-Optimization-Algorithms">https://github.com/mynkpl1998/Deep-Learning-Optimization-Algorithms</a></td>
</tr>
<tr>
<td style="text-align:left"><strong>Some visualizations</strong>:</td>
</tr>
<tr>
<td style="text-align:left"><img loading="lazy" src="https://github.com/mynkpl1998/Deep-Learning-Optimization-Algorithms/raw/master/Images/convex_sgd.gif" alt="alt-text-1"  title="SGD on convex-surface"  />
 <img loading="lazy" src="https://github.com/mynkpl1998/Deep-Learning-Optimization-Algorithms/raw/master/Images/non_convex_sgd.gif" alt="alt-text-2"  title="SGD on non-convex surface"  />
</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left">Recurrent Deep-Q Learning</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>Description</strong>: Partially Observable Markov Decision Process (POMDP) is a generalization of Markov Decision Process where agent cannot directly observe the underlying state and only an observation is available. Earlier methods suggests to maintain a belief (a pmf) over all the possible states which encodes the probability of being in each state. This quickly limits the size of the problem to which we can use this method. However, the paper Playing Atari with Deep Reinforcement Learning presented an approach which uses last 4 observations as input to the learning algorithm, which can be seen as 4th order markov decision process. Many papers suggest that much performance can be obtained if we use more than last 4 frames but this is expensive from computational and storage point of view (experience replay). Recurrent networks can be used to summarize what agent has seen in past observations. In this project, I investgated this using a simple Partially Observable Environment and found that using a single recurrent layer able to achieve much better performance than using some last k-frames. <!-- raw HTML omitted --> <strong>Source Code</strong>: <a href="https://github.com/mynkpl1998/Recurrent-Deep-Q-Learning">https://github.com/mynkpl1998/Recurrent-Deep-Q-Learning</a> <!-- raw HTML omitted --> <strong>Results</strong>: The figure given below compares the performance of different cases. MDP case is the best we can do as the underlying state is fully visible to the agent. However, the challenge is to perform better given an observation. The graph clearly shows the LSTM consistently performed better as the total reward per episode was much higher than using some last k-frames. <!-- raw HTML omitted --> <!-- raw HTML omitted --> <img loading="lazy" src="https://raw.githubusercontent.com/mynkpl1998/Recurrent-Deep-Q-Learning/master/data/GIFs/perf.png" alt="alt-text-4"  title="Performance difference using LSTM network against past k-frames"  />
</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left"><a href="https://github.com/mynkpl1998/Deep-RL-Framework/blob/master/examples/1.%20Walk%20Through%20Demo%20-%20DQN%20-%20Fixed%20Epsilon.ipynb">A Deep Reinforcement Learning Framework</a></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>Description</strong>: This framework implements the various state of the art Value based Deep Reinforcement Learning algorithms, supports OpenAI gym environments out of the box. Implementation include Deep-Q learning, Deep-Q learning with target freezing, Prioritized experience replay, Double Q-learning. <!-- raw HTML omitted --> <strong>Source Code</strong>: <a href="https://github.com/mynkpl1998/Deep-RL-Framework">https://github.com/mynkpl1998/Deep-RL-Framework</a></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left"><a href="https://github.com/mynkpl1998/A3C/tree/dev">Asynchronous Actor-Critic (A3C) - Policy Gradients Methods</a></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>Description</strong>: High quality implementation of A3C algorithm with Generalized Advantage Estimation. Supports different neural network based policies out of the box. Performance of the algorithm scales linearly with the number of cores. <!-- raw HTML omitted --> <strong>Source Code</strong>: <a href="https://github.com/mynkpl1998/A3C/tree/dev">https://github.com/mynkpl1998/A3C/tree/dev</a> <!-- raw HTML omitted --> <strong>Trained Policies</strong>: <!-- raw HTML omitted --> <!-- raw HTML omitted --> <img loading="lazy" src="https://raw.githubusercontent.com/mynkpl1998/mynkpl1998.github.io/master/images/cartpole.gif" alt="alt-text-5"  title="Cartpole - keep the pole in vertical position"  />
 <img loading="lazy" src="https://raw.githubusercontent.com/mynkpl1998/mynkpl1998.github.io/master/images/lander.gif" alt="alt-text-6"  title="Lunar Lander - land between flags"  />
</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left">Deep learning for Physical layer</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>Description</strong>: We present and discuss the application of Deep Learning (DL) for the physical layer. By interpreting a communication system as an AutoEncoder, we develop a fundamental new way to think about communications system design as end-to-end reconstruction task that seeks to jointly optimize transmitter and receiver components in a single process.  Simulations were done to illustrate the learning of the deep networks. Further, the results were compared with traditional methods. <!-- raw HTML omitted --> <strong>Report</strong>: <a href="https://drive.google.com/file/d/1q3Ba741gZxWAgv4t7ERwb5H93iajp2J-/view">https://drive.google.com/file/d/1q3Ba741gZxWAgv4t7ERwb5H93iajp2J-/view</a> <!-- raw HTML omitted --> <strong>Modeling communication system as end-to-end learning system</strong>: <!-- raw HTML omitted --> <!-- raw HTML omitted --> <img loading="lazy" src="https://raw.githubusercontent.com/mynkpl1998/mynkpl1998.github.io/master/images/model.jpg" alt="alt-text-9"  title="Blocks of a communication system"  />
 <img loading="lazy" src="https://raw.githubusercontent.com/mynkpl1998/mynkpl1998.github.io/master/images/arch.jpg" alt="alt-text-10"  title="End-to-end learning based model of a communication system"  />
</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left">Implemention of Convolutional and Recurrent neural networks inference for Heterogeneous Devices (GPU and FPGA) using OpenCL</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>Description</strong>: Many devices today have more than one processor other than CPUs to accelerate certain workloads. For example, an integrated graphics or DSPs in an embedded system. This creates an interesting opportunity for deep learning community to take advantage of it and use it to accelerate the inference/training process for edge devices. We attempted to implement the inference of some of the known architecture like Recurrent and Convolutional neural networks for FPGA and GPU in Open Compute Language trained on standard datasets. <!-- raw HTML omitted --> <strong>CNN Source Code</strong>: <a href="https://bitbucket.org/mynkpl1998/vgg_opencl/src/master/">https://bitbucket.org/mynkpl1998/vgg_opencl/src/master/</a> <!-- raw HTML omitted --> <strong>RNN Source Code</strong>: <a href="https://bitbucket.org/mynkpl1998/rnn_opencl/src/master/">https://bitbucket.org/mynkpl1998/rnn_opencl/src/master/</a> <!-- raw HTML omitted --> <strong>CNN Report</strong>: <a href="https://drive.google.com/file/d/1yDCyucwo6I5Z2bOd-tKOkEWo-ByrFHdc/view">https://drive.google.com/file/d/1yDCyucwo6I5Z2bOd-tKOkEWo-ByrFHdc/view</a> <!-- raw HTML omitted --> <strong>RNN Report</strong>: <a href="https://drive.google.com/file/d/1GzoLjMLM-rKMvbgFPtIJ7b3X_wivbxfw/view">https://drive.google.com/file/d/1GzoLjMLM-rKMvbgFPtIJ7b3X_wivbxfw/view</a> <!-- raw HTML omitted --> <strong>Results</strong>: The following screnshots shows the running time in case of GPU(left) and resource usage in FPGA(right). <!-- raw HTML omitted --> <!-- raw HTML omitted --> <img loading="lazy" src="https://raw.githubusercontent.com/mynkpl1998/mynkpl1998.github.io/master/images/cnn.png" alt="alt-text-7"  title="Running time of each kernel (GPU)"  />
 <img loading="lazy" src="https://raw.githubusercontent.com/mynkpl1998/mynkpl1998.github.io/master/images/rnn.png" alt="alt-text-8"  title="Resource usage by each kernel (FPGA)"  />
</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left"><a href="https://github.com/mynkpl1998/atppredict">ATP-Predict</a></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>Description</strong>: We carried out a brief implementation of the paper Identification of ATP binding residues of a protein from its primary sequence and attempted to improve on the existing methods by using different machine learning techniques using an extended dataset and optimized parameters on the models.  We obtained maximum cross-validation accuracy of around 0.64 on a balanced data-set, with window size 17. <!-- raw HTML omitted --> <strong>Project Web Page</strong>: <a href="https://mynkpl1998.github.io/atppredict/">https://mynkpl1998.github.io/atppredict/</a></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left">Cancer Prediction using Deep Neural Networks</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>Description</strong>: This project investigates the opportunities of applying the deep convolutional networks fordeveloping prediction model for cancer prediction. We selected high quality image dataset containing both benign and malignant examples. We build a classifier which used SIFT to extract the features from the images. However, we found that this naive approach could not able to perform well on our dataset. We  then explored the space of Deep Learning techniques specifically Deep Convolutional Neural Networks. <!-- raw HTML omitted --> <strong>Report</strong>: <a href="https://drive.google.com/file/d/1W24dv9um3QGnfZsEoDO-jFaOmISeWiDF/view">https://drive.google.com/file/d/1W24dv9um3QGnfZsEoDO-jFaOmISeWiDF/view</a><!-- raw HTML omitted --> <strong>Results</strong>: <!-- raw HTML omitted --> <img loading="lazy" src="https://raw.githubusercontent.com/mynkpl1998/mynkpl1998.github.io/master/images/trainingStat.jpg" alt="alt-text-12"  title="Training statistics"  />
 <img loading="lazy" src="https://raw.githubusercontent.com/mynkpl1998/mynkpl1998.github.io/master/images/confMat.jpg" alt="alt-text-11"  title="Confusion maxtrix of  CNN based classifier"  />
</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left"><a href="https://github.com/mynkpl1998/visualize-vgg16">Visualizing VGG16 feature maps in Keras</a></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>Description</strong>: This project impelements the code for visualizing the feature maps of VGG16 Convoutional Neural Network using Keras. Particular layer of the network can be visualized by defining it as an output layer. For brevity please check some examples given below. <!-- raw HTML omitted --> <strong>Source Code</strong>: <a href="https://github.com/mynkpl1998/visualize-vgg16">https://github.com/mynkpl1998/visualize-vgg16</a> <!-- raw HTML omitted --> <strong>Feature maps</strong>: <!-- raw HTML omitted --> <img loading="lazy" src="https://raw.githubusercontent.com/mynkpl1998/mynkpl1998.github.io/master/images/glass_maps.png" alt="alt-text-12"  title="Beer glass"  />
 <img loading="lazy" src="https://raw.githubusercontent.com/mynkpl1998/mynkpl1998.github.io/master/images/bear_maps.png" alt="alt-text-11"  title="Bear"  />
</td>
</tr>
</tbody>
</table>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://mynkpl1998.github.io/">Mayank Kumar Pal</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
</body>

</html>
